# Generated by Django 5.2.3 on 2025-10-05 01:30

import django.db.models.deletion
from django.conf import settings
from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('prompts', '0018_alter_prompt_order'),
        ('taggit', '0006_rename_taggeditem_content_type_object_id_taggit_tagg_content_8fc721_idx'),
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
    ]

    operations = [
        migrations.CreateModel(
            name='ContentFlag',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('category', models.CharField(help_text='Type of inappropriate content detected', max_length=100)),
                ('confidence', models.FloatField(help_text='Confidence score for this specific detection')),
                ('details', models.JSONField(blank=True, default=dict, help_text='Additional metadata about this flag')),
                ('severity', models.CharField(choices=[('low', 'Low'), ('medium', 'Medium'), ('high', 'High'), ('critical', 'Critical')], default='medium', max_length=20)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
            ],
            options={
                'ordering': ['-confidence', '-created_at'],
            },
        ),
        migrations.CreateModel(
            name='ModerationLog',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('service', models.CharField(choices=[('rekognition', 'AWS Rekognition'), ('cloudinary_ai', 'Cloudinary AI Vision'), ('openai', 'OpenAI Moderation API')], help_text='Which AI moderation service was used', max_length=50)),
                ('status', models.CharField(choices=[('pending', 'Pending Review'), ('approved', 'Approved'), ('rejected', 'Rejected'), ('flagged', 'Flagged for Manual Review')], default='pending', max_length=20)),
                ('confidence_score', models.FloatField(blank=True, help_text='AI confidence score (0.0 to 1.0)', null=True)),
                ('flagged_categories', models.JSONField(blank=True, default=list, help_text='Categories or labels flagged by the AI')),
                ('raw_response', models.JSONField(blank=True, default=dict, help_text='Full API response for debugging')),
                ('moderated_at', models.DateTimeField(auto_now_add=True)),
                ('notes', models.TextField(blank=True, help_text='Admin notes or additional context')),
            ],
            options={
                'ordering': ['-moderated_at'],
            },
        ),
        migrations.AddField(
            model_name='prompt',
            name='moderation_completed_at',
            field=models.DateTimeField(blank=True, help_text='When all moderation checks were completed', null=True),
        ),
        migrations.AddField(
            model_name='prompt',
            name='moderation_status',
            field=models.CharField(choices=[('pending', 'Pending Review'), ('approved', 'Approved'), ('rejected', 'Rejected'), ('flagged', 'Flagged for Manual Review')], default='pending', help_text='Overall moderation status for this prompt', max_length=20),
        ),
        migrations.AddField(
            model_name='prompt',
            name='requires_manual_review',
            field=models.BooleanField(default=False, help_text='Flagged for admin manual review'),
        ),
        migrations.AddField(
            model_name='prompt',
            name='review_notes',
            field=models.TextField(blank=True, help_text='Admin notes from manual review'),
        ),
        migrations.AddField(
            model_name='prompt',
            name='reviewed_by',
            field=models.ForeignKey(blank=True, help_text='Admin who manually reviewed this prompt', null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='reviewed_prompts', to=settings.AUTH_USER_MODEL),
        ),
        migrations.AddIndex(
            model_name='prompt',
            index=models.Index(fields=['moderation_status'], name='prompts_pro_moderat_dded1e_idx'),
        ),
        migrations.AddIndex(
            model_name='prompt',
            index=models.Index(fields=['requires_manual_review'], name='prompts_pro_require_9d1d5a_idx'),
        ),
        migrations.AddField(
            model_name='moderationlog',
            name='prompt',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='moderation_logs', to='prompts.prompt'),
        ),
        migrations.AddField(
            model_name='contentflag',
            name='moderation_log',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='flags', to='prompts.moderationlog'),
        ),
        migrations.AddIndex(
            model_name='moderationlog',
            index=models.Index(fields=['prompt', 'service'], name='prompts_mod_prompt__a700f7_idx'),
        ),
        migrations.AddIndex(
            model_name='moderationlog',
            index=models.Index(fields=['status'], name='prompts_mod_status_ebc311_idx'),
        ),
        migrations.AddIndex(
            model_name='moderationlog',
            index=models.Index(fields=['moderated_at'], name='prompts_mod_moderat_561759_idx'),
        ),
        migrations.AddIndex(
            model_name='contentflag',
            index=models.Index(fields=['category', 'severity'], name='prompts_con_categor_353a35_idx'),
        ),
    ]
